{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc798029-5881-4812-bf33-775741336170",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-16 15:58:15.587291: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2026-01-16 15:58:15.604574: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1768575495.614663   58718 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1768575495.618026   58718 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1768575495.626689   58718 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1768575495.626702   58718 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1768575495.626703   58718 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1768575495.626705   58718 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2026-01-16 15:58:15.629684: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import shutil\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c963500-ba28-4697-ba91-fe9925080a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_array_as_image(array, title=\"Preprocessed Image\"):\n",
    "    reshaped_array = array.reshape(28, 28)\n",
    "\n",
    "    plt.imshow(reshaped_array, cmap='gray')\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def class_to_char_emnist_bymerge(class_idx):\n",
    "    \"\"\"\n",
    "    Convert EMNIST bymerge class index to character.\n",
    "    The mapping is based on the dataset's official character set.\n",
    "    \"\"\"\n",
    "    # EMNIST bymerge mapping (A-Z, then a-z, then 0-9) with merged cases\n",
    "    # This is the official mapping from the EMNIST documentation\n",
    "    mapping = {\n",
    "        0: '0', 1: '1', 2: '2', 3: '3', 4: '4', 5: '5', 6: '6', 7: '7', 8: '8', 9: '9',\n",
    "        10: 'A', 11: 'B', 12: 'C', 13: 'D', 14: 'E', 15: 'F', 16: 'G', 17: 'H', 18: 'I',\n",
    "        19: 'J', 20: 'K', 21: 'L', 22: 'M', 23: 'N', 24: 'O', 25: 'P', 26: 'Q', 27: 'R',\n",
    "        28: 'S', 29: 'T', 30: 'U', 31: 'V', 32: 'W', 33: 'X', 34: 'Y', 35: 'Z',\n",
    "        36: 'a', 37: 'b', 38: 'd', 39: 'e', 40: 'f', 41: 'g', 42: 'h', 43: 'n', 44: 'q',\n",
    "        45: 'r', 46: 't'\n",
    "    }\n",
    "    \n",
    "    # Check if the index is valid\n",
    "    if class_idx in mapping:\n",
    "        return mapping[class_idx]\n",
    "    else:\n",
    "        return \"?\" # Return a placeholder for an unknown index\n",
    "\n",
    "def class_to_char(class_idx):\n",
    "    \"\"\"Convert class index to character (A-Z: 0-25, 0-9: 26-35)\"\"\"\n",
    "    if class_idx < 10:\n",
    "        return str(class_idx)\n",
    "    else:\n",
    "        return chr(class_idx + 55)\n",
    "        \n",
    "def class_to_char_alpha(class_idx):\n",
    "    \"\"\"Convert class index to character (A-Z: 0-25, 0-9: 26-35)\"\"\"\n",
    "    return chr(class_idx+65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909078a6-1ea7-4d2f-8a7b-ce5a426606eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2a1501c-d29d-46e3-a2d1-ef241fb2e480",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load('models/sklearn_logistic_regression/model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a20f063d-129d-4245-90f0-ce5d5d22c04a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-16 15:58:20.226555: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    }
   ],
   "source": [
    "base_dir_cnn = \"models/cnn/\"\n",
    "alpha = \"alpha_cnn.h5\"\n",
    "alpha2 = \"alpha_recognition_cnn2.h5\"\n",
    "alpha3 = \"alpha_recognition_cnn3.h5\"\n",
    "alpha4 = \"alpha_test_50_cnn.keras\"\n",
    "alphanum = \"alphanum_cnn.h5\"\n",
    "alphanum2 = \"alphanum_recognition_cnn.h5\"\n",
    "alphanum3 = \"alphanum_regularized_cnn.h5\"\n",
    "alphanum4 = \"alpha_recognition_cnn2.h5\"\n",
    "emnist = \"emnist_cnn.h5\"\n",
    "emnist_az = \"\"\n",
    "emnist_az_reduced = \"eminst_a-z_reduced_cnn.h5\"\n",
    "\n",
    "\n",
    "cnn_model = tf.keras.models.load_model(base_dir_cnn + alpha4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6eeae6e5-1cba-4bf2-add6-0939ec2a2f57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image, ImageOps\n",
    "\n",
    "def preprocess_image_for_cnn(image_path):\n",
    "    \"\"\"\n",
    "    Loads an image from a given path, preprocesses it, and converts it\n",
    "    to a NumPy array suitable for CNN model prediction.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        img = Image.open(image_path)\n",
    "        img = img.convert('L')\n",
    "        img = img.resize((28, 28), Image.LANCZOS)\n",
    "        img_array = np.array(img, dtype=np.float32) / 255.0\n",
    "        # Invert the pixel values to match the dataset (white on black)\n",
    "        img_array = 1.0 - img_array\n",
    "        \n",
    "        # --- Display the 2D array as an image (if function exists) ---\n",
    "        #display_array_as_image(img_array) \n",
    "        \n",
    "        # Reshape for CNN: (1, 28, 28, 1) instead of flattening\n",
    "        cnn_array = img_array.reshape(1, 28, 28, 1)\n",
    "        return cnn_array\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file at {image_path} was not found.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "def preprocess_image_for_cnn2(image_path):\n",
    "    try:\n",
    "        img = Image.open(image_path)\n",
    "        img = img.convert('L')\n",
    "        \n",
    "        img_np = np.array(img, dtype=np.uint8)\n",
    "\n",
    "        _, img_binary = cv2.threshold(img_np, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "        \n",
    "        kernel = np.ones((3, 3), np.uint8)\n",
    "        img_dilated_binary = cv2.dilate(img_binary, kernel, iterations=3)\n",
    "        \n",
    "        img_pil_dilated = Image.fromarray(img_dilated_binary)\n",
    "\n",
    "        img = img_pil_dilated.resize((28, 28), Image.LANCZOS)\n",
    "        img_array = np.array(img, dtype=np.float32) / 255.0\n",
    "        \n",
    "        display_array_as_image(img_array) \n",
    "        \n",
    "        cnn_array = img_array.reshape(1, 28, 28, 1)\n",
    "        return cnn_array\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file at {image_path} was not found.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "def preprocess_image_for_cnn3(image_path):\n",
    "    \"\"\"\n",
    "    Loads an image from a given path, preprocesses it, and converts it\n",
    "    to a NumPy array suitable for CNN model prediction.\n",
    "    Applies EMNIST-specific transformations: 90° clockwise rotation and vertical flip.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        img = Image.open(image_path)\n",
    "        img = img.convert('L')\n",
    "        img = img.resize((28, 28), Image.LANCZOS)\n",
    "\n",
    "        \"\"\"\n",
    "        img_array1 = np.array(img, dtype=np.float32) / 255.0\n",
    "        # Invert the pixel values to match the dataset (white on black)\n",
    "        img_array1 = 1.0 - img_array1\n",
    "        \n",
    "        # --- Display the 2D array as an image (if function exists) ---\n",
    "        display_array_as_image(img_array1)\n",
    "        \"\"\"\n",
    "        \n",
    "        # Apply EMNIST transformations\n",
    "        img = img.rotate(90, expand=False)  # Rotate 90° clockwise (-90)\n",
    "        img = img.transpose(Image.FLIP_TOP_BOTTOM)  # Flip vertically\n",
    "        \n",
    "        img_array = np.array(img, dtype=np.float32) / 255.0\n",
    "        # Invert the pixel values to match the dataset (white on black)\n",
    "        img_array = 1.0 - img_array\n",
    "        \n",
    "        # --- Display the 2D array as an image (if function exists) ---\n",
    "        # display_array_as_image(img_array) \n",
    "        \n",
    "        # Reshape for CNN: (1, 28, 28, 1) instead of flattening\n",
    "        cnn_array = img_array.reshape(1, 28, 28, 1)\n",
    "        return cnn_array\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file at {image_path} was not found.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c04b3b1-c50d-48c0-931b-10dc54a233a9",
   "metadata": {},
   "source": [
    "### WITHOUT FALSE POSITIVES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b2e4c870-19f7-41c4-85d5-e173c8c22003",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def benchmark_model(test_data_directory=\"testing_data/benchmark1\"):\n",
    "    \"\"\"\n",
    "    Benchmark the model by testing it on sorted data and calculating accuracy\n",
    "    \n",
    "    Args:\n",
    "        test_data_directory: Directory containing sorted character folders\n",
    "    \"\"\"\n",
    "    \n",
    "    if not os.path.exists(test_data_directory):\n",
    "        print(f\"Error: Test data directory '{test_data_directory}' not found!\")\n",
    "        return\n",
    "    \n",
    "    # Get all character folders\n",
    "    character_folders = [f for f in os.listdir(test_data_directory) \n",
    "                        if os.path.isdir(os.path.join(test_data_directory, f))]\n",
    "    \n",
    "    if not character_folders:\n",
    "        print(\"No character folders found in test directory!\")\n",
    "        return\n",
    "    \n",
    "    character_folders.sort()\n",
    "    \n",
    "    total_correct = 0\n",
    "    total_images = 0\n",
    "    overall_results = {}\n",
    "    \n",
    "    print(f\"Benchmarking model on {len(character_folders)} character classes...\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for true_char in character_folders:\n",
    "        folder_path = os.path.join(test_data_directory, true_char)\n",
    "        \n",
    "        # Get all image files in this character folder\n",
    "        image_files = []\n",
    "        \n",
    "        for filename in os.listdir(folder_path):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            if os.path.isfile(file_path):\n",
    "                image_files.append(filename)\n",
    "        \n",
    "        if not image_files:\n",
    "            print(f\"No images found in folder '{true_char}'\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\nTesting character '{true_char}' ({len(image_files)} images):\")\n",
    "        \n",
    "        # Dictionary to count predictions for this character\n",
    "        prediction_counts = {}\n",
    "        correct_predictions = 0\n",
    "        \n",
    "        for filename in image_files:\n",
    "            image_path = os.path.join(folder_path, filename)\n",
    "            preprocessed_image = preprocess_image_for_cnn(image_path)\n",
    "            \n",
    "            if preprocessed_image is not None:\n",
    "                # Get prediction\n",
    "                prediction_proba = cnn_model.predict(preprocessed_image, verbose=0)\n",
    "                predicted_class_id = np.argmax(prediction_proba[0])\n",
    "                predicted_char = class_to_char(predicted_class_id)\n",
    "                confidence = np.max(prediction_proba[0])\n",
    "                \n",
    "                # Count predictions\n",
    "                if predicted_char in prediction_counts:\n",
    "                    prediction_counts[predicted_char] += 1\n",
    "                else:\n",
    "                    prediction_counts[predicted_char] = 1\n",
    "                \n",
    "                # Check if prediction is correct\n",
    "                if predicted_char == true_char:\n",
    "                    correct_predictions += 1\n",
    "                \n",
    "                total_images += 1\n",
    "        \n",
    "        # Calculate accuracy for this character\n",
    "        folder_accuracy = (correct_predictions / len(image_files)) * 100 if image_files else 0\n",
    "        total_correct += correct_predictions\n",
    "        \n",
    "        # Display results for this character\n",
    "        print(f\"Predictions for '{true_char}':\")\n",
    "        sorted_predictions = sorted(prediction_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "        for pred_char, count in sorted_predictions:\n",
    "            percentage = (count / len(image_files)) * 100\n",
    "            marker = \"✓\" if pred_char == true_char else \"✗\"\n",
    "            print(f\"  {marker} {pred_char}: {count} times ({percentage:.1f}%)\")\n",
    "        \n",
    "        print(f\"Accuracy for '{true_char}': {correct_predictions}/{len(image_files)} ({folder_accuracy:.1f}%)\")\n",
    "        \n",
    "        # Store overall results\n",
    "        overall_results[true_char] = {\n",
    "            'total_images': len(image_files),\n",
    "            'correct_predictions': correct_predictions,\n",
    "            'accuracy': folder_accuracy,\n",
    "            'predictions': prediction_counts\n",
    "        }\n",
    "    \n",
    "    # Calculate and display overall accuracy\n",
    "    overall_accuracy = (total_correct / total_images) * 100 if total_images > 0 else 0\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"BENCHMARK SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Total images tested: {total_images}\")\n",
    "    print(f\"Total correct predictions: {total_correct}\")\n",
    "    print(f\"Overall accuracy: {overall_accuracy:.2f}%\")\n",
    "    \n",
    "    # Display per-character summary\n",
    "    print(\"\\nPer-character accuracy:\")\n",
    "    for char, results in overall_results.items():\n",
    "        print(f\"  {char}: {results['accuracy']:.1f}% ({results['correct_predictions']}/{results['total_images']})\")\n",
    "    \n",
    "    # Find best and worst performing characters\n",
    "    if overall_results:\n",
    "        best_char = max(overall_results.items(), key=lambda x: x[1]['accuracy'])\n",
    "        worst_char = min(overall_results.items(), key=lambda x: x[1]['accuracy'])\n",
    "        \n",
    "        print(f\"\\nBest performing: '{best_char[0]}' ({best_char[1]['accuracy']:.1f}%)\")\n",
    "        print(f\"Worst performing: '{worst_char[0]}' ({worst_char[1]['accuracy']:.1f}%)\")\n",
    "    \n",
    "    return overall_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c29902-85ef-4605-b7c3-21db229a82b1",
   "metadata": {},
   "source": [
    "### FALSE POSITIVES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0a568d5b-1feb-4bfa-a782-2749eee2c6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_model_fp(test_data_directory=\"testing_data/benchmark1\"):\n",
    "    \"\"\"\n",
    "    Benchmark the model by testing it on sorted data and calculating accuracy and\n",
    "    false positives per class.\n",
    "    \n",
    "    Args:\n",
    "        test_data_directory: Directory containing sorted character folders\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import numpy as np\n",
    "    # NOTE: cnn_model, preprocess_image_for_cnn, and class_to_char must be defined globally\n",
    "    # or passed as arguments for this function to run.\n",
    "    \n",
    "    if not os.path.exists(test_data_directory):\n",
    "        print(f\"Error: Test data directory '{test_data_directory}' not found!\")\n",
    "        return\n",
    "    \n",
    "    # Get all character folders\n",
    "    character_folders = [f for f in os.listdir(test_data_directory) \n",
    "                         if os.path.isdir(os.path.join(test_data_directory, f))]\n",
    "    \n",
    "    if not character_folders:\n",
    "        print(\"No character folders found in test directory!\")\n",
    "        return\n",
    "    \n",
    "    character_folders.sort()\n",
    "    \n",
    "    total_correct = 0\n",
    "    total_images = 0\n",
    "    overall_results = {}\n",
    "    \n",
    "    # Initialize a dictionary to track False Positives across ALL classes\n",
    "    false_positives = {char: 0 for char in character_folders}\n",
    "    \n",
    "    print(f\"Benchmarking model on {len(character_folders)} character classes...\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for true_char in character_folders:\n",
    "        folder_path = os.path.join(test_data_directory, true_char)\n",
    "        \n",
    "        # Get all image files in this character folder\n",
    "        image_files = []\n",
    "        \n",
    "        for filename in os.listdir(folder_path):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            if os.path.isfile(file_path):\n",
    "                image_files.append(filename)\n",
    "        \n",
    "        if not image_files:\n",
    "            print(f\"No images found in folder '{true_char}'\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\nTesting character '{true_char}' ({len(image_files)} images):\")\n",
    "        \n",
    "        # Dictionary to count predictions for this character\n",
    "        prediction_counts = {}\n",
    "        correct_predictions = 0\n",
    "        \n",
    "        for filename in image_files:\n",
    "            image_path = os.path.join(folder_path, filename)\n",
    "            preprocessed_image = preprocess_image_for_cnn(image_path)\n",
    "            \n",
    "            if preprocessed_image is not None:\n",
    "                # Get prediction\n",
    "                prediction_proba = cnn_model.predict(preprocessed_image, verbose=0)\n",
    "                predicted_class_id = np.argmax(prediction_proba[0])\n",
    "                predicted_char = class_to_char(predicted_class_id)\n",
    "                confidence = np.max(prediction_proba[0])\n",
    "                \n",
    "                # Count predictions\n",
    "                if predicted_char in prediction_counts:\n",
    "                    prediction_counts[predicted_char] += 1\n",
    "                else:\n",
    "                    prediction_counts[predicted_char] = 1\n",
    "                \n",
    "                # Check if prediction is correct\n",
    "                if predicted_char == true_char:\n",
    "                    correct_predictions += 1\n",
    "                else:\n",
    "                    # Increment False Positive count for the PREDICTED character\n",
    "                    false_positives[predicted_char] += 1\n",
    "                \n",
    "                total_images += 1\n",
    "        \n",
    "        # Calculate accuracy for this character\n",
    "        folder_accuracy = (correct_predictions / len(image_files)) * 100 if image_files else 0\n",
    "        total_correct += correct_predictions\n",
    "        \n",
    "        # Display results for this character\n",
    "        print(f\"Predictions for '{true_char}':\")\n",
    "        sorted_predictions = sorted(prediction_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "        for pred_char, count in sorted_predictions:\n",
    "            percentage = (count / len(image_files)) * 100\n",
    "            marker = \"✓\" if pred_char == true_char else \"✗\"\n",
    "            print(f\"  {marker} {pred_char}: {count} times ({percentage:.1f}%)\")\n",
    "        \n",
    "        print(f\"Accuracy for '{true_char}': {correct_predictions}/{len(image_files)} ({folder_accuracy:.1f}%)\")\n",
    "        \n",
    "        # Store overall results\n",
    "        overall_results[true_char] = {\n",
    "            'total_images': len(image_files),\n",
    "            'correct_predictions': correct_predictions,\n",
    "            'accuracy': folder_accuracy,\n",
    "            'predictions': prediction_counts\n",
    "        }\n",
    "    \n",
    "    # Calculate and display overall accuracy\n",
    "    overall_accuracy = (total_correct / total_images) * 100 if total_images > 0 else 0\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"BENCHMARK SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Total images tested: {total_images}\")\n",
    "    print(f\"Total correct predictions: {total_correct}\")\n",
    "    print(f\"Overall accuracy: {overall_accuracy:.2f}%\")\n",
    "    \n",
    "    # Display per-character summary\n",
    "    print(\"\\nPer-character summary:\")\n",
    "    for char in character_folders:\n",
    "        results = overall_results.get(char, {'accuracy': 0.0, 'correct_predictions': 0, 'total_images': 0})\n",
    "        fp_count = false_positives.get(char, 0)\n",
    "        \n",
    "        print(f\"  {char}: Acc={results['accuracy']:.1f}% ({results['correct_predictions']}/{results['total_images']}), FP={fp_count}\")\n",
    "        \n",
    "        # Store False Positives in the results structure\n",
    "        overall_results[char]['false_positives'] = fp_count\n",
    "        \n",
    "    \n",
    "    # Find best and worst performing characters (unchanged)\n",
    "    if overall_results:\n",
    "        best_char = max(overall_results.items(), key=lambda x: x[1]['accuracy'])\n",
    "        worst_char = min(overall_results.items(), key=lambda x: x[1]['accuracy'])\n",
    "        \n",
    "        print(f\"\\nBest performing: '{best_char[0]}' ({best_char[1]['accuracy']:.1f}%)\")\n",
    "        print(f\"Worst performing: '{worst_char[0]}' ({worst_char[1]['accuracy']:.1f}%)\")\n",
    "    \n",
    "    return overall_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa098d5-d2e7-4224-a5dd-5392cc09bb3d",
   "metadata": {},
   "source": [
    "### FALSE POSITIVES WITH DETAILS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d12ba788-9099-47a1-932c-70f11217e3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def benchmark_model_fp_details(test_data_directory=\"testing_data/benchmark1\"):\n",
    "    \"\"\"\n",
    "    Benchmark the model by testing it on sorted data and calculating accuracy and\n",
    "    detailed false positives per class.\n",
    "    \n",
    "    Args:\n",
    "        test_data_directory: Directory containing sorted character folders\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import numpy as np\n",
    "    # NOTE: cnn_model, preprocess_image_for_cnn, and class_to_char must be defined globally\n",
    "    # or passed as arguments for this function to run.\n",
    "    \n",
    "    if not os.path.exists(test_data_directory):\n",
    "        print(f\"Error: Test data directory '{test_data_directory}' not found!\")\n",
    "        return\n",
    "    \n",
    "    # Get all character folders\n",
    "    character_folders = [f for f in os.listdir(test_data_directory) \n",
    "                         if os.path.isdir(os.path.join(test_data_directory, f))]\n",
    "    \n",
    "    if not character_folders:\n",
    "        print(\"No character folders found in test directory!\")\n",
    "        return\n",
    "    \n",
    "    character_folders.sort()\n",
    "    \n",
    "    total_correct = 0\n",
    "    total_images = 0\n",
    "    overall_results = {}\n",
    "    \n",
    "    # NEW: Initialize a dictionary to track False Positives in detail.\n",
    "    # Structure: {predicted_char: {true_char: count, ...}, ...}\n",
    "    detailed_false_positives = {char: {} for char in character_folders}\n",
    "    \n",
    "    print(f\"Benchmarking model on {len(character_folders)} character classes...\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for true_char in character_folders:\n",
    "        folder_path = os.path.join(test_data_directory, true_char)\n",
    "        \n",
    "        # Get all image files in this character folder\n",
    "        image_files = []\n",
    "        for filename in os.listdir(folder_path):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            if os.path.isfile(file_path):\n",
    "                image_files.append(filename)\n",
    "        \n",
    "        if not image_files:\n",
    "            print(f\"No images found in folder '{true_char}'\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\nTesting character '{true_char}' ({len(image_files)} images):\")\n",
    "        \n",
    "        # Dictionary to count predictions for this character (True Positive + False Negatives)\n",
    "        prediction_counts = {}\n",
    "        correct_predictions = 0\n",
    "        \n",
    "        for filename in image_files:\n",
    "            image_path = os.path.join(folder_path, filename)\n",
    "            preprocessed_image = preprocess_image_for_cnn3(image_path)\n",
    "            \n",
    "            if preprocessed_image is not None:\n",
    "                # Get prediction\n",
    "                prediction_proba = cnn_model.predict(preprocessed_image, verbose=0)\n",
    "                predicted_class_id = np.argmax(prediction_proba[0])\n",
    "                predicted_char = class_to_char(predicted_class_id)\n",
    "                confidence = np.max(prediction_proba[0])\n",
    "                \n",
    "                # Count predictions\n",
    "                prediction_counts[predicted_char] = prediction_counts.get(predicted_char, 0) + 1\n",
    "                \n",
    "                # Check if prediction is correct\n",
    "                if predicted_char == true_char:\n",
    "                    correct_predictions += 1\n",
    "                else:\n",
    "                    # NEW: Update the detailed False Positive tracker\n",
    "                    # The model predicted 'predicted_char' when the true label was 'true_char'\n",
    "                    if true_char in detailed_false_positives[predicted_char]:\n",
    "                        detailed_false_positives[predicted_char][true_char] += 1\n",
    "                    else:\n",
    "                        detailed_false_positives[predicted_char][true_char] = 1\n",
    "                \n",
    "                total_images += 1\n",
    "        \n",
    "        # Calculate accuracy for this character\n",
    "        folder_accuracy = (correct_predictions / len(image_files)) * 100 if image_files else 0\n",
    "        total_correct += correct_predictions\n",
    "        \n",
    "        # Display results for this character\n",
    "        print(f\"Predictions for '{true_char}':\")\n",
    "        sorted_predictions = sorted(prediction_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "        for pred_char, count in sorted_predictions:\n",
    "            percentage = (count / len(image_files)) * 100\n",
    "            marker = \"✓\" if pred_char == true_char else \"✗\"\n",
    "            print(f\"  {marker} {pred_char}: {count} times ({percentage:.1f}%)\")\n",
    "        \n",
    "        print(f\"Accuracy for '{true_char}': {correct_predictions}/{len(image_files)} ({folder_accuracy:.1f}%)\")\n",
    "        \n",
    "        # Store results\n",
    "        overall_results[true_char] = {\n",
    "            'total_images': len(image_files),\n",
    "            'correct_predictions': correct_predictions,\n",
    "            'accuracy': folder_accuracy,\n",
    "            'predictions': prediction_counts\n",
    "        }\n",
    "    \n",
    "    # Calculate and display overall accuracy\n",
    "    overall_accuracy = (total_correct / total_images) * 100 if total_images > 0 else 0\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"BENCHMARK SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Total images tested: {total_images}\")\n",
    "    print(f\"Total correct predictions: {total_correct}\")\n",
    "    print(f\"Overall accuracy: {overall_accuracy:.2f}%\")\n",
    "    \n",
    "    # Display per-character summary including detailed FPs\n",
    "    print(\"\\nPer-character summary (Accuracy & Confusion):\")\n",
    "    for char in character_folders:\n",
    "        results = overall_results.get(char, {'accuracy': 0.0, 'correct_predictions': 0, 'total_images': 0})\n",
    "        fp_details = detailed_false_positives.get(char, {})\n",
    "        \n",
    "        # Calculate total False Positives for this character (how many times it was predicted incorrectly)\n",
    "        total_fp = sum(fp_details.values())\n",
    "        \n",
    "        # Format the detailed FP string (e.g., \"4-Y, 2-U\")\n",
    "        fp_list = []\n",
    "        if total_fp > 0:\n",
    "            # Sort by count descending for readability\n",
    "            sorted_fp = sorted(fp_details.items(), key=lambda x: x[1], reverse=True)\n",
    "            fp_list = [f\"{count}-{true_char}\" for true_char, count in sorted_fp]\n",
    "            \n",
    "        fp_str = \", \".join(fp_list) if fp_list else \"None\"\n",
    "        \n",
    "        print(f\"  {char}: Acc={results['accuracy']:.1f}% ({results['correct_predictions']}/{results['total_images']})\")\n",
    "        print(f\"      FP ({total_fp}): {fp_str}\")\n",
    "        \n",
    "        # Store False Positives in the results structure\n",
    "        overall_results[char]['false_positives_total'] = total_fp\n",
    "        overall_results[char]['false_positives_details'] = fp_details\n",
    "    \n",
    "    # Find best and worst performing characters (unchanged)\n",
    "    if overall_results:\n",
    "        best_char = max(overall_results.items(), key=lambda x: x[1]['accuracy'])\n",
    "        worst_char = min(overall_results.items(), key=lambda x: x[1]['accuracy'])\n",
    "        \n",
    "        print(f\"\\nBest performing: '{best_char[0]}' ({best_char[1]['accuracy']:.1f}%)\")\n",
    "        print(f\"Worst performing: '{worst_char[0]}' ({worst_char[1]['accuracy']:.1f}%)\")\n",
    "    overall_accuracy = (total_correct / total_images) * 100 if total_images > 0 else 0\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"BENCHMARK SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Total images tested: {total_images}\")\n",
    "    print(f\"Total correct predictions: {total_correct}\")\n",
    "    print(f\"Overall accuracy: {overall_accuracy:.2f}%\") # <-- THIS IS THE FINAL METRIC\n",
    "    \n",
    "    return overall_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f2122f-6164-40cd-a861-dd51c32761bd",
   "metadata": {},
   "source": [
    "### EMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2819f455-c911-4551-beb2-f3aed33255ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def benchmark_model_emnist(test_data_directory=\"testing_data/benchmark1\"):\n",
    "    \"\"\"\n",
    "    Benchmark the model by testing it on sorted data and calculating accuracy and\n",
    "    detailed false positives per class.\n",
    "    \n",
    "    Args:\n",
    "        test_data_directory: Directory containing sorted character folders\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import numpy as np\n",
    "    # NOTE: cnn_model, preprocess_image_for_cnn, and class_to_char must be defined globally\n",
    "    # or passed as arguments for this function to run.\n",
    "    \n",
    "    if not os.path.exists(test_data_directory):\n",
    "        print(f\"Error: Test data directory '{test_data_directory}' not found!\")\n",
    "        return\n",
    "    \n",
    "    # Get all character folders\n",
    "    character_folders = [f for f in os.listdir(test_data_directory) \n",
    "                         if os.path.isdir(os.path.join(test_data_directory, f))]\n",
    "    \n",
    "    if not character_folders:\n",
    "        print(\"No character folders found in test directory!\")\n",
    "        return\n",
    "    \n",
    "    character_folders.sort()\n",
    "    \n",
    "    total_correct = 0\n",
    "    total_images = 0\n",
    "    overall_results = {}\n",
    "    \n",
    "    # Get all possible predicted characters from EMNIST (including lowercase)\n",
    "    # This assumes class_to_char can return all possible characters\n",
    "    all_possible_chars = set(character_folders)  # Start with folders that exist\n",
    "    \n",
    "    # We'll dynamically add predicted characters as we encounter them\n",
    "    detailed_false_positives = {}\n",
    "    \n",
    "    print(f\"Benchmarking model on {len(character_folders)} character classes...\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for true_char in character_folders:\n",
    "        folder_path = os.path.join(test_data_directory, true_char)\n",
    "        \n",
    "        # Get all image files in this character folder\n",
    "        image_files = []\n",
    "        for filename in os.listdir(folder_path):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            if os.path.isfile(file_path):\n",
    "                image_files.append(filename)\n",
    "        \n",
    "        if not image_files:\n",
    "            print(f\"No images found in folder '{true_char}'\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\nTesting character '{true_char}' ({len(image_files)} images):\")\n",
    "        \n",
    "        # Dictionary to count predictions for this character (True Positive + False Negatives)\n",
    "        prediction_counts = {}\n",
    "        correct_predictions = 0\n",
    "        \n",
    "        for filename in image_files:\n",
    "            image_path = os.path.join(folder_path, filename)\n",
    "            preprocessed_image = preprocess_image_for_cnn3(image_path)\n",
    "            \n",
    "            if preprocessed_image is not None:\n",
    "                # Get prediction\n",
    "                prediction_proba = cnn_model.predict(preprocessed_image, verbose=0)\n",
    "                predicted_class_id = np.argmax(prediction_proba[0])\n",
    "                predicted_char = class_to_char_emnist_bymerge(predicted_class_id)\n",
    "                confidence = np.max(prediction_proba[0])\n",
    "                \n",
    "                # Count predictions\n",
    "                prediction_counts[predicted_char] = prediction_counts.get(predicted_char, 0) + 1\n",
    "                \n",
    "                # Check if prediction is correct\n",
    "                if predicted_char == true_char:\n",
    "                    correct_predictions += 1\n",
    "                else:\n",
    "                    # Initialize the predicted_char entry if it doesn't exist\n",
    "                    if predicted_char not in detailed_false_positives:\n",
    "                        detailed_false_positives[predicted_char] = {}\n",
    "                    \n",
    "                    # Update the detailed False Positive tracker\n",
    "                    if true_char in detailed_false_positives[predicted_char]:\n",
    "                        detailed_false_positives[predicted_char][true_char] += 1\n",
    "                    else:\n",
    "                        detailed_false_positives[predicted_char][true_char] = 1\n",
    "                \n",
    "                total_images += 1\n",
    "        \n",
    "        # Calculate accuracy for this character\n",
    "        folder_accuracy = (correct_predictions / len(image_files)) * 100 if image_files else 0\n",
    "        total_correct += correct_predictions\n",
    "        \n",
    "        # Display results for this character\n",
    "        print(f\"Predictions for '{true_char}':\")\n",
    "        sorted_predictions = sorted(prediction_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "        for pred_char, count in sorted_predictions:\n",
    "            percentage = (count / len(image_files)) * 100\n",
    "            marker = \"✓\" if pred_char == true_char else \"✗\"\n",
    "            print(f\"  {marker} {pred_char}: {count} times ({percentage:.1f}%)\")\n",
    "        \n",
    "        print(f\"Accuracy for '{true_char}': {correct_predictions}/{len(image_files)} ({folder_accuracy:.1f}%)\")\n",
    "        \n",
    "        # Store results\n",
    "        overall_results[true_char] = {\n",
    "            'total_images': len(image_files),\n",
    "            'correct_predictions': correct_predictions,\n",
    "            'accuracy': folder_accuracy,\n",
    "            'predictions': prediction_counts\n",
    "        }\n",
    "    \n",
    "    # Calculate and display overall accuracy\n",
    "    overall_accuracy = (total_correct / total_images) * 100 if total_images > 0 else 0\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"BENCHMARK SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Total images tested: {total_images}\")\n",
    "    print(f\"Total correct predictions: {total_correct}\")\n",
    "    print(f\"Overall accuracy: {overall_accuracy:.2f}%\")\n",
    "    \n",
    "    # Display per-character summary including detailed FPs\n",
    "    print(\"\\nPer-character summary (Accuracy & Confusion):\")\n",
    "    print(\"Note: Only showing characters that exist in test folders\")\n",
    "    for char in character_folders:\n",
    "        results = overall_results.get(char, {'accuracy': 0.0, 'correct_predictions': 0, 'total_images': 0})\n",
    "        fp_details = detailed_false_positives.get(char, {})\n",
    "        \n",
    "        # Calculate total False Positives for this character (how many times it was predicted incorrectly)\n",
    "        total_fp = sum(fp_details.values())\n",
    "        \n",
    "        # Format the detailed FP string (e.g., \"4-Y, 2-U\")\n",
    "        fp_list = []\n",
    "        if total_fp > 0:\n",
    "            # Sort by count descending for readability\n",
    "            sorted_fp = sorted(fp_details.items(), key=lambda x: x[1], reverse=True)\n",
    "            fp_list = [f\"{count}-{true_char}\" for true_char, count in sorted_fp]\n",
    "            \n",
    "        fp_str = \", \".join(fp_list) if fp_list else \"None\"\n",
    "        \n",
    "        print(f\"  {char}: Acc={results['accuracy']:.1f}% ({results['correct_predictions']}/{results['total_images']})\")\n",
    "        print(f\"      FP ({total_fp}): {fp_str}\")\n",
    "        \n",
    "        # Store False Positives in the results structure\n",
    "        overall_results[char]['false_positives_total'] = total_fp\n",
    "        overall_results[char]['false_positives_details'] = fp_details\n",
    "    \n",
    "    # Find best and worst performing characters\n",
    "    if overall_results:\n",
    "        best_char = max(overall_results.items(), key=lambda x: x[1]['accuracy'])\n",
    "        worst_char = min(overall_results.items(), key=lambda x: x[1]['accuracy'])\n",
    "        \n",
    "        print(f\"\\nBest performing: '{best_char[0]}' ({best_char[1]['accuracy']:.1f}%)\")\n",
    "        print(f\"Worst performing: '{worst_char[0]}' ({worst_char[1]['accuracy']:.1f}%)\")\n",
    "    \n",
    "    # Show any lowercase predictions that were made but don't have folders\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"PREDICTED LOWERCASE CHARACTERS (no test folders):\")\n",
    "    print(\"=\"*60)\n",
    "    lowercase_predictions = {char: fp_details for char, fp_details in detailed_false_positives.items() \n",
    "                            if char not in character_folders and char.islower()}\n",
    "    \n",
    "    if lowercase_predictions:\n",
    "        for pred_char, true_char_dict in sorted(lowercase_predictions.items()):\n",
    "            total = sum(true_char_dict.values())\n",
    "            confused_with = \", \".join([f\"{count}-{tc}\" for tc, count in sorted(true_char_dict.items(), key=lambda x: x[1], reverse=True)])\n",
    "            print(f\"  '{pred_char}' was predicted {total} times\")\n",
    "            print(f\"      Confused with: {confused_with}\")\n",
    "    else:\n",
    "        print(\"  No lowercase predictions detected\")\n",
    "    \n",
    "    return overall_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd051ce-66b7-4d21-bb0d-e33309126026",
   "metadata": {},
   "source": [
    "### ALPHA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c972b74b-2be3-4d6c-8ff9-0c4054ed71aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def benchmark_alpha(test_data_directory=\"testing_data/benchmark1\"):\n",
    "    \"\"\"\n",
    "    Benchmark the alpha model by testing it on sorted data and calculating accuracy and\n",
    "    detailed false positives per class. Only processes alphabetic character folders.\n",
    "    \n",
    "    Args:\n",
    "        test_data_directory: Directory containing sorted character folders\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import numpy as np\n",
    "    # NOTE: cnn_model_alpha, preprocess_image_for_cnn, and class_to_char_alpha must be defined globally\n",
    "    # or passed as arguments for this function to run.\n",
    "    \n",
    "    if not os.path.exists(test_data_directory):\n",
    "        print(f\"Error: Test data directory '{test_data_directory}' not found!\")\n",
    "        return\n",
    "    \n",
    "    # Get all character folders - ONLY ALPHA CHARACTERS\n",
    "    all_folders = [f for f in os.listdir(test_data_directory) \n",
    "                   if os.path.isdir(os.path.join(test_data_directory, f))]\n",
    "    \n",
    "    # Filter to only alphabetic characters\n",
    "    character_folders = [f for f in all_folders if f.isalpha() and len(f) == 1]\n",
    "    \n",
    "    if not character_folders:\n",
    "        print(\"No alpha character folders found in test directory!\")\n",
    "        return\n",
    "    \n",
    "    character_folders.sort()\n",
    "    \n",
    "    total_correct = 0\n",
    "    total_images = 0\n",
    "    overall_results = {}\n",
    "    \n",
    "    # NEW: Initialize a dictionary to track False Positives in detail.\n",
    "    # Structure: {predicted_char: {true_char: count, ...}, ...}\n",
    "    detailed_false_positives = {char: {} for char in character_folders}\n",
    "    \n",
    "    print(f\"Benchmarking alpha model on {len(character_folders)} alphabetic character classes...\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for true_char in character_folders:\n",
    "        folder_path = os.path.join(test_data_directory, true_char)\n",
    "        \n",
    "        # Get all image files in this character folder\n",
    "        image_files = []\n",
    "        for filename in os.listdir(folder_path):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            if os.path.isfile(file_path):\n",
    "                image_files.append(filename)\n",
    "        \n",
    "        if not image_files:\n",
    "            print(f\"No images found in folder '{true_char}'\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\nTesting character '{true_char}' ({len(image_files)} images):\")\n",
    "        \n",
    "        # Dictionary to count predictions for this character (True Positive + False Negatives)\n",
    "        prediction_counts = {}\n",
    "        correct_predictions = 0\n",
    "        \n",
    "        for filename in image_files:\n",
    "            image_path = os.path.join(folder_path, filename)\n",
    "            preprocessed_image = preprocess_image_for_cnn(image_path)\n",
    "            \n",
    "            if preprocessed_image is not None:\n",
    "                # Get prediction using alpha model                \n",
    "                #print(f\"Preprocessed image shape: {preprocessed_image.shape}\")\n",
    "\n",
    "                prediction_proba = cnn_model.predict(preprocessed_image, verbose=0)\n",
    "                predicted_class_id = np.argmax(prediction_proba[0])\n",
    "                predicted_char = class_to_char_alpha(predicted_class_id)\n",
    "                confidence = np.max(prediction_proba[0])\n",
    "                \n",
    "                # Count predictions\n",
    "                prediction_counts[predicted_char] = prediction_counts.get(predicted_char, 0) + 1\n",
    "                \n",
    "                # Check if prediction is correct\n",
    "                if predicted_char == true_char:\n",
    "                    correct_predictions += 1\n",
    "                else:\n",
    "                    # NEW: Update the detailed False Positive tracker\n",
    "                    # The model predicted 'predicted_char' when the true label was 'true_char'\n",
    "                    if true_char in detailed_false_positives[predicted_char]:\n",
    "                        detailed_false_positives[predicted_char][true_char] += 1\n",
    "                    else:\n",
    "                        detailed_false_positives[predicted_char][true_char] = 1\n",
    "                \n",
    "                total_images += 1\n",
    "        \n",
    "        # Calculate accuracy for this character\n",
    "        folder_accuracy = (correct_predictions / len(image_files)) * 100 if image_files else 0\n",
    "        total_correct += correct_predictions\n",
    "        \n",
    "        # Display results for this character\n",
    "        print(f\"Predictions for '{true_char}':\")\n",
    "        sorted_predictions = sorted(prediction_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "        for pred_char, count in sorted_predictions:\n",
    "            percentage = (count / len(image_files)) * 100\n",
    "            marker = \"✓\" if pred_char == true_char else \"✗\"\n",
    "            print(f\"  {marker} {pred_char}: {count} times ({percentage:.1f}%)\")\n",
    "        \n",
    "        print(f\"Accuracy for '{true_char}': {correct_predictions}/{len(image_files)} ({folder_accuracy:.1f}%)\")\n",
    "        \n",
    "        # Store results\n",
    "        overall_results[true_char] = {\n",
    "            'total_images': len(image_files),\n",
    "            'correct_predictions': correct_predictions,\n",
    "            'accuracy': folder_accuracy,\n",
    "            'predictions': prediction_counts\n",
    "        }\n",
    "    \n",
    "    # Calculate and display overall accuracy\n",
    "    overall_accuracy = (total_correct / total_images) * 100 if total_images > 0 else 0\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"BENCHMARK SUMMARY (ALPHA MODEL)\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Total images tested: {total_images}\")\n",
    "    print(f\"Total correct predictions: {total_correct}\")\n",
    "    print(f\"Overall accuracy: {overall_accuracy:.2f}%\")\n",
    "    \n",
    "    # Display per-character summary including detailed FPs\n",
    "    print(\"\\nPer-character summary (Accuracy & Confusion):\")\n",
    "    for char in character_folders:\n",
    "        results = overall_results.get(char, {'accuracy': 0.0, 'correct_predictions': 0, 'total_images': 0})\n",
    "        fp_details = detailed_false_positives.get(char, {})\n",
    "        \n",
    "        # Calculate total False Positives for this character (how many times it was predicted incorrectly)\n",
    "        total_fp = sum(fp_details.values())\n",
    "        \n",
    "        # Format the detailed FP string (e.g., \"4-Y, 2-U\")\n",
    "        fp_list = []\n",
    "        if total_fp > 0:\n",
    "            # Sort by count descending for readability\n",
    "            sorted_fp = sorted(fp_details.items(), key=lambda x: x[1], reverse=True)\n",
    "            fp_list = [f\"{count}-{true_char}\" for true_char, count in sorted_fp]\n",
    "            \n",
    "        fp_str = \", \".join(fp_list) if fp_list else \"None\"\n",
    "        \n",
    "        print(f\"  {char}: Acc={results['accuracy']:.1f}% ({results['correct_predictions']}/{results['total_images']})\")\n",
    "        print(f\"      FP ({total_fp}): {fp_str}\")\n",
    "        \n",
    "        # Store False Positives in the results structure\n",
    "        overall_results[char]['false_positives_total'] = total_fp\n",
    "        overall_results[char]['false_positives_details'] = fp_details\n",
    "    \n",
    "    # Find best and worst performing characters\n",
    "    if overall_results:\n",
    "        best_char = max(overall_results.items(), key=lambda x: x[1]['accuracy'])\n",
    "        worst_char = min(overall_results.items(), key=lambda x: x[1]['accuracy'])\n",
    "        \n",
    "        print(f\"\\nBest performing: '{best_char[0]}' ({best_char[1]['accuracy']:.1f}%)\")\n",
    "        print(f\"Worst performing: '{worst_char[0]}' ({worst_char[1]['accuracy']:.1f}%)\")\n",
    "    \n",
    "    overall_accuracy = (total_correct / total_images) * 100 if total_images > 0 else 0\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"BENCHMARK SUMMARY (ALPHA MODEL)\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Total images tested: {total_images}\")\n",
    "    print(f\"Total correct predictions: {total_correct}\")\n",
    "    print(f\"Overall accuracy: {overall_accuracy:.2f}%\") # <-- THIS IS THE FINAL METRIC\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6ee899-83ec-40e6-bc41-bd836f3f19d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir_cnn = \"models/cnn/\"\n",
    "alpha = \"alpha_cnn.h5\"\n",
    "alpha2 = \"alpha_recognition_cnn2.h5\"\n",
    "alpha3 = \"alpha_recognition_cnn3.h5\"\n",
    "alpha4 = \"alpha_test_50_cnn.keras\"\n",
    "alphanum = \"alphanum_cnn.h5\"\n",
    "alphanum2 = \"alphanum_recognition_cnn.h5\"\n",
    "alphanum3 = \"alphanum_regularized_cnn.h5\"\n",
    "alphanum4 = \"alpha_recognition_cnn2.h5\"\n",
    "emnist = \"emnist_cnn.h5\"\n",
    "emnist_az = \"\"\n",
    "emnist_az_reduced = \"eminst_a-z_reduced_cnn.h5\"\n",
    "\n",
    "\n",
    "cnn_model = tf.keras.models.load_model(base_dir_cnn + alpha4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "00995f4a-8d15-44d3-a04c-e352d2d0308e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmarking alpha model on 26 alphabetic character classes...\n",
      "============================================================\n",
      "\n",
      "Testing character 'A' (174 images):\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Predictions for 'A':\n",
      "  ✓ A: 166 times (95.4%)\n",
      "  ✗ M: 3 times (1.7%)\n",
      "  ✗ P: 2 times (1.1%)\n",
      "  ✗ H: 2 times (1.1%)\n",
      "  ✗ N: 1 times (0.6%)\n",
      "Accuracy for 'A': 166/174 (95.4%)\n",
      "\n",
      "Testing character 'B' (27 images):\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Predictions for 'B':\n",
      "  ✓ B: 27 times (100.0%)\n",
      "Accuracy for 'B': 27/27 (100.0%)\n",
      "\n",
      "Testing character 'C' (42 images):\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Predictions for 'C':\n",
      "  ✓ C: 41 times (97.6%)\n",
      "  ✗ S: 1 times (2.4%)\n",
      "Accuracy for 'C': 41/42 (97.6%)\n",
      "\n",
      "Testing character 'D' (74 images):\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n",
      "Preprocessed image shape: (1, 28, 28, 1)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m benchmark_alpha()\n",
      "Cell \u001b[0;32mIn[24], line 72\u001b[0m, in \u001b[0;36mbenchmark_alpha\u001b[0;34m(test_data_directory)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m preprocessed_image \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# Get prediction using alpha model                \u001b[39;00m\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPreprocessed image shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpreprocessed_image\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 72\u001b[0m     prediction_proba \u001b[38;5;241m=\u001b[39m cnn_model\u001b[38;5;241m.\u001b[39mpredict(preprocessed_image, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     73\u001b[0m     predicted_class_id \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(prediction_proba[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     74\u001b[0m     predicted_char \u001b[38;5;241m=\u001b[39m class_to_char_alpha(predicted_class_id)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:499\u001b[0m, in \u001b[0;36mTensorFlowTrainer.predict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;129m@traceback_utils\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_traceback\n\u001b[1;32m    495\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\n\u001b[1;32m    496\u001b[0m     \u001b[38;5;28mself\u001b[39m, x, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m, steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, callbacks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    497\u001b[0m ):\n\u001b[1;32m    498\u001b[0m     \u001b[38;5;66;03m# Create an iterator that yields batches of input data.\u001b[39;00m\n\u001b[0;32m--> 499\u001b[0m     epoch_iterator \u001b[38;5;241m=\u001b[39m TFEpochIterator(\n\u001b[1;32m    500\u001b[0m         x\u001b[38;5;241m=\u001b[39mx,\n\u001b[1;32m    501\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m    502\u001b[0m         steps_per_epoch\u001b[38;5;241m=\u001b[39msteps,\n\u001b[1;32m    503\u001b[0m         shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    504\u001b[0m         distribute_strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy,\n\u001b[1;32m    505\u001b[0m         steps_per_execution\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps_per_execution,\n\u001b[1;32m    506\u001b[0m     )\n\u001b[1;32m    508\u001b[0m     \u001b[38;5;66;03m# Container that configures and calls callbacks.\u001b[39;00m\n\u001b[1;32m    509\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(callbacks, callbacks_module\u001b[38;5;241m.\u001b[39mCallbackList):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:720\u001b[0m, in \u001b[0;36mTFEpochIterator.__init__\u001b[0;34m(self, distribute_strategy, *args, **kwargs)\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    719\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_distribute_strategy \u001b[38;5;241m=\u001b[39m distribute_strategy\n\u001b[0;32m--> 720\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_adapter\u001b[38;5;241m.\u001b[39mget_tf_dataset()\n\u001b[1;32m    721\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dataset, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedDataset):\n\u001b[1;32m    722\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_distribute_strategy\u001b[38;5;241m.\u001b[39mexperimental_distribute_dataset(\n\u001b[1;32m    723\u001b[0m         dataset\n\u001b[1;32m    724\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/keras/src/trainers/data_adapters/array_data_adapter.py:235\u001b[0m, in \u001b[0;36mArrayDataAdapter.get_tf_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    233\u001b[0m     indices_dataset \u001b[38;5;241m=\u001b[39m indices_dataset\u001b[38;5;241m.\u001b[39mmap(tf\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mshuffle)\n\u001b[0;32m--> 235\u001b[0m dataset \u001b[38;5;241m=\u001b[39m slice_inputs(indices_dataset, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inputs)\n\u001b[1;32m    237\u001b[0m options \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mOptions()\n\u001b[1;32m    238\u001b[0m options\u001b[38;5;241m.\u001b[39mexperimental_distribute\u001b[38;5;241m.\u001b[39mauto_shard_policy \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    239\u001b[0m     tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mAutoShardPolicy\u001b[38;5;241m.\u001b[39mDATA\n\u001b[1;32m    240\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/keras/src/trainers/data_adapters/array_data_adapter.py:214\u001b[0m, in \u001b[0;36mArrayDataAdapter.get_tf_dataset.<locals>.slice_inputs\u001b[0;34m(indices_dataset, inputs)\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[1;32m    212\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tree\u001b[38;5;241m.\u001b[39mtraverse(grab_one, data)\n\u001b[0;32m--> 214\u001b[0m dataset \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mmap(\n\u001b[1;32m    215\u001b[0m     grab_batch, num_parallel_calls\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mAUTOTUNE\n\u001b[1;32m    216\u001b[0m )\n\u001b[1;32m    218\u001b[0m \u001b[38;5;66;03m# Default optimizations are disabled to avoid the overhead of\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;66;03m# (unnecessary) input pipeline graph serialization & deserialization\u001b[39;00m\n\u001b[1;32m    220\u001b[0m options \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mOptions()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/tensorflow/python/data/ops/dataset_ops.py:2341\u001b[0m, in \u001b[0;36mDatasetV2.map\u001b[0;34m(self, map_func, num_parallel_calls, deterministic, synchronous, use_unbounded_threadpool, name)\u001b[0m\n\u001b[1;32m   2336\u001b[0m \u001b[38;5;66;03m# Loaded lazily due to a circular dependency (dataset_ops -> map_op ->\u001b[39;00m\n\u001b[1;32m   2337\u001b[0m \u001b[38;5;66;03m# dataset_ops).\u001b[39;00m\n\u001b[1;32m   2338\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top,protected-access\u001b[39;00m\n\u001b[1;32m   2339\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m map_op\n\u001b[0;32m-> 2341\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m map_op\u001b[38;5;241m.\u001b[39m_map_v2(\n\u001b[1;32m   2342\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2343\u001b[0m     map_func,\n\u001b[1;32m   2344\u001b[0m     num_parallel_calls\u001b[38;5;241m=\u001b[39mnum_parallel_calls,\n\u001b[1;32m   2345\u001b[0m     deterministic\u001b[38;5;241m=\u001b[39mdeterministic,\n\u001b[1;32m   2346\u001b[0m     synchronous\u001b[38;5;241m=\u001b[39msynchronous,\n\u001b[1;32m   2347\u001b[0m     use_unbounded_threadpool\u001b[38;5;241m=\u001b[39muse_unbounded_threadpool,\n\u001b[1;32m   2348\u001b[0m     name\u001b[38;5;241m=\u001b[39mname,\n\u001b[1;32m   2349\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/tensorflow/python/data/ops/map_op.py:57\u001b[0m, in \u001b[0;36m_map_v2\u001b[0;34m(input_dataset, map_func, num_parallel_calls, deterministic, synchronous, use_unbounded_threadpool, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synchronous:\n\u001b[1;32m     52\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     53\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`synchronous` is not supported with `num_parallel_calls`, but\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     54\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `num_parallel_calls` was set to \u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     55\u001b[0m       num_parallel_calls,\n\u001b[1;32m     56\u001b[0m   )\n\u001b[0;32m---> 57\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _ParallelMapDataset(\n\u001b[1;32m     58\u001b[0m     input_dataset,\n\u001b[1;32m     59\u001b[0m     map_func,\n\u001b[1;32m     60\u001b[0m     num_parallel_calls\u001b[38;5;241m=\u001b[39mnum_parallel_calls,\n\u001b[1;32m     61\u001b[0m     deterministic\u001b[38;5;241m=\u001b[39mdeterministic,\n\u001b[1;32m     62\u001b[0m     preserve_cardinality\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     63\u001b[0m     use_unbounded_threadpool\u001b[38;5;241m=\u001b[39muse_unbounded_threadpool,\n\u001b[1;32m     64\u001b[0m     name\u001b[38;5;241m=\u001b[39mname)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/tensorflow/python/data/ops/map_op.py:218\u001b[0m, in \u001b[0;36m_ParallelMapDataset.__init__\u001b[0;34m(self, input_dataset, map_func, num_parallel_calls, deterministic, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, use_unbounded_threadpool, name)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_unbounded_threadpool \u001b[38;5;241m=\u001b[39m use_unbounded_threadpool\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name \u001b[38;5;241m=\u001b[39m name\n\u001b[0;32m--> 218\u001b[0m variant_tensor \u001b[38;5;241m=\u001b[39m gen_dataset_ops\u001b[38;5;241m.\u001b[39mparallel_map_dataset_v2(\n\u001b[1;32m    219\u001b[0m     input_dataset\u001b[38;5;241m.\u001b[39m_variant_tensor,  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func\u001b[38;5;241m.\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs,\n\u001b[1;32m    221\u001b[0m     f\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func\u001b[38;5;241m.\u001b[39mfunction,\n\u001b[1;32m    222\u001b[0m     num_parallel_calls\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_parallel_calls,\n\u001b[1;32m    223\u001b[0m     deterministic\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_deterministic,\n\u001b[1;32m    224\u001b[0m     use_inter_op_parallelism\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_inter_op_parallelism,\n\u001b[1;32m    225\u001b[0m     preserve_cardinality\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preserve_cardinality,\n\u001b[1;32m    226\u001b[0m     use_unbounded_threadpool\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_unbounded_threadpool,\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_common_args)\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(input_dataset, variant_tensor)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/tensorflow/python/ops/gen_dataset_ops.py:5866\u001b[0m, in \u001b[0;36mparallel_map_dataset_v2\u001b[0;34m(input_dataset, other_arguments, num_parallel_calls, f, output_types, output_shapes, use_inter_op_parallelism, deterministic, preserve_cardinality, use_unbounded_threadpool, metadata, name)\u001b[0m\n\u001b[1;32m   5864\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[1;32m   5865\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 5866\u001b[0m     _result \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_FastPathExecute(\n\u001b[1;32m   5867\u001b[0m       _ctx, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParallelMapDatasetV2\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, input_dataset, other_arguments,\n\u001b[1;32m   5868\u001b[0m       num_parallel_calls, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m, f, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_types\u001b[39m\u001b[38;5;124m\"\u001b[39m, output_types,\n\u001b[1;32m   5869\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_shapes\u001b[39m\u001b[38;5;124m\"\u001b[39m, output_shapes, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_inter_op_parallelism\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   5870\u001b[0m       use_inter_op_parallelism, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeterministic\u001b[39m\u001b[38;5;124m\"\u001b[39m, deterministic,\n\u001b[1;32m   5871\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpreserve_cardinality\u001b[39m\u001b[38;5;124m\"\u001b[39m, preserve_cardinality,\n\u001b[1;32m   5872\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_unbounded_threadpool\u001b[39m\u001b[38;5;124m\"\u001b[39m, use_unbounded_threadpool, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   5873\u001b[0m       metadata)\n\u001b[1;32m   5874\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m   5875\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "benchmark_alpha()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
